<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Louis  Sharrock</title>
    <meta name="author" content="Louis  Sharrock">
    <meta name="description" content="Senior Research Associate in Statistical Machine Learning.
">
    <meta name="keywords" content="louis-sharrock, personal-website, computational-statistics, machine-learning">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://louissharrock.github.io/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item active">
                <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">cv</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/">teaching</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- about.html -->
      <div class="post">
        <header class="post-header">
          <h1 class="post-title">
           <span class="font-weight-bold">Louis</span>  Sharrock
          </h1>
          <p class="desc">Senior Research Associate in Statistical Machine Learning</p>
        </header>

        <article>
          <div class="profile float-right">

              <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/profile-pic-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/profile-pic-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/profile-pic-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/profile-pic.jpg" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="profile-pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

            <div class="address">
              <p>Fry Building</p> <p>Woodland Road</p> <p>Bristol, BS8 1UG</p>

            </div>
          </div>

          <div class="clearfix">
            <p><strong>About</strong>. I am a Senior Research Associate in Statistical Machine Learning working with <a href="https://chris-nemeth.github.io/" rel="external nofollow noopener" target="_blank">Prof. Chris Nemeth</a> at Lancaster University, and an Honorary Senior Research Associate at the University of Bristol. I was previously a Data Science Heilbronn Research Fellow at the University of Bristol. I obtained my PhD in the Department of Mathematics at Imperial College London, supervised by <a href="http://wwwf.imperial.ac.uk/~nkantas/" rel="external nofollow noopener" target="_blank">Dr. Nikolas Kantas</a>. I hold an MRes in Mathematics and an MSc in Statistics from Imperial College London, and an MA in Mathematics from the University of Cambridge.</p>

<p><strong>Research</strong>. My research interests include computational statistics, machine learning, and optimisation, with a particular focus on stochastic gradient Markov Chain Monte Carlo methods and likelihood free inference. My current research focuses on learning-rate free sampling algorithms, score-based methods for simulation based inference, and online inference for interacting particle systems and mean-field equations.</p>

          </div>

          <!-- News -->
          <h2><a href="/news/" style="color: inherit;">news</a></h2>          <div class="news">
            <div class="table-responsive" style="max-height: 60vw">
              <table class="table table-sm table-borderless">
              
                <tr>
                  <th scope="row">May 1, 2024</th>
                  <td>
                    We have two papers - “<a href="https://arxiv.org/abs/2210.04872" rel="external nofollow noopener" target="_blank">Sequential Neural Score Estimation: Likelihood-Free Inference with Conditional Score Based Diffusion Models</a>” and “<a href="https://arxiv.org/abs/2406.02296" rel="external nofollow noopener" target="_blank">Learning-Rate-Free Stochastic Optimization over Riemannian Manifolds</a>” - accepted as spotlights to ICML 2024!

                  </td>
                </tr>
                <tr>
                  <th scope="row">Jan 19, 2024</th>
                  <td>
                    Our paper - “<a href="https://proceedings.mlr.press/v238/sharrock24a.html" rel="external nofollow noopener" target="_blank">Tuning-Free Maximum Likelihood Training of Latent Variable Models via Coin Betting</a>” - has been accepted to AISTATS 2024!

                  </td>
                </tr>
                <tr>
                  <th scope="row">Oct 20, 2023</th>
                  <td>
                    We are organising an exciting workshop at the RSS on <em>Gradient Flows for Sampling, Inference, and Learning</em>. Click <a href="https://rss.org.uk/training-events/events/events-2023/sections/gradient-flows-for-sampling,-inference,-and-learni/#eventoverview" rel="external nofollow noopener" target="_blank">here</a> for more details.

                  </td>
                </tr>
                <tr>
                  <th scope="row">Sep 21, 2023</th>
                  <td>
                    Our paper - “<a href="https://openreview.net/forum?id=TNAGFUcSP7" rel="external nofollow noopener" target="_blank">Learning Rate Free Sampling in Constrained Domains</a>” - has been accepted to NeurIPS 2023!

                  </td>
                </tr>
                <tr>
                  <th scope="row">Sep 8, 2023</th>
                  <td>
                    In Feb 2024, I will give an invited talk on parameter-free optimisation on the space of probability measures at <a href="https://ismp2024.gerad.ca/" rel="external nofollow noopener" target="_blank">ISMP 2024</a>.

                  </td>
                </tr>
                <tr>
                  <th scope="row">Aug 14, 2023</th>
                  <td>
                    In Feb 2024, I will give an invited talk on online parameter estimation for interacting particle systems at the <a href="https://www.siam.org/conferences/cm/conference/uq24" rel="external nofollow noopener" target="_blank">SIAM Conference on Uncertainty Quantification</a>.

                  </td>
                </tr>
                <tr>
                  <th scope="row">May 24, 2023</th>
                  <td>
                    We have two new preprints up on arXiv! Check them out <a href="https://arxiv.org/abs/2305.14943" rel="external nofollow noopener" target="_blank">here</a> and <a href="https://arxiv.org/abs/2305.14916" rel="external nofollow noopener" target="_blank">here</a>.

                  </td>
                </tr>
                <tr>
                  <th scope="row">May 3, 2023</th>
                  <td>
                    Our paper - “<a href="https://www.sciencedirect.com/science/article/pii/S0304414923000972" rel="external nofollow noopener" target="_blank">Online Parameter Estimation for the McKean-Vlasov Stochastic Differential Equation</a>” - has been accepted to Stochastic Processes and their Applications.

                  </td>
                </tr>
              </table>
            </div>
          </div>

          <!-- Latest posts -->
          

          <!-- Selected papers -->
          <h2><a href="/publications/" style="color: inherit;">selected publications</a></h2>
          <div class="publications">
            <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge"><a href="https://www.sciencedirect.com/journal/stochastic-processes-and-their-applications" rel="external nofollow noopener" target="_blank">SPA</a></abbr></div>

        <!-- Entry bib key -->
        <div id="Sharrock2021a" class="col-sm-8">
        <!-- Title -->
        <div class="title">Online Parameter Estimation for the McKean-Vlasov Stochastic Differential Equation</div>
        <!-- Author -->
        <div class="author">
        

        <em>Louis Sharrock</em>, <a href="https://www.ma.imperial.ac.uk/~nkantas/" rel="external nofollow noopener" target="_blank">Nikolas Kantas</a>, <a href="https://www.doc.ic.ac.uk/~pp500/" rel="external nofollow noopener" target="_blank">Panos Parpas</a>, and <a href="https://www.ma.imperial.ac.uk/~pavl/" rel="external nofollow noopener" target="_blank">Grigorios A. Pavliotis</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Stochastic Processes and their Applications</em>, 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2106.13751" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="https://www.sciencedirect.com/science/article/pii/S0304414923000972" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
            <a href="https://github.com/louissharrock/Parameter-Estimation-for-Interacting-Particle-Systems" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
            <a href="/assets/pdf/mvsde-slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-altmetric-id="false"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We analyse the problem of online parameter estimation for a stochastic McKean–Vlasov equation, and the associated system of weakly interacting particles. We propose an online estimator for the parameters of the McKean–Vlasov SDE, or the interacting particle system, which is based on a continuous-time stochastic gradient ascent scheme with respect to the asymptotic log-likelihood of the interacting particle system. We characterise the asymptotic behaviour of this estimator in the limit as T→∞, and also in the joint limit as  T→∞and N→∞. In these two cases, we obtain almost sure or L_1 convergence to the stationary points of a limiting contrast function, under suitable conditions which guarantee ergodicity and uniform-in-time propagation of chaos. We also establish, under the additional condition of global strong concavity, L_2 convergence to the unique maximiser of the asymptotic log-likelihood of the McKean–Vlasov SDE, with an asymptotic convergence rate which depends on the learning rate, the number of observations, and the dimension of the non-linear process. Our theoretical results are supported by two numerical examples, a linear mean field model and a stochastic opinion dynamics model.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge"><a href="https://projecteuclid.org/journals/bernoulli" rel="external nofollow noopener" target="_blank">Bernoulli</a></abbr></div>

        <!-- Entry bib key -->
        <div id="Sharrock2020a" class="col-sm-8">
        <!-- Title -->
        <div class="title">Two-timescale stochastic gradient descent in continuous time with applications to joint online parameter estimation and optimal sensor placement</div>
        <!-- Author -->
        <div class="author">
        

        <em>Louis Sharrock</em>, and <a href="https://www.ma.imperial.ac.uk/~nkantas/" rel="external nofollow noopener" target="_blank">Nikolas Kantas</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Bernoulli</em>, 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2007.15998" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="https://projecteuclid.org/journals/bernoulli/volume-29/issue-2/Two-timescale-stochastic-gradient-descent-in-continuous-time-with-applications/10.3150/22-BEJ1493.full" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-altmetric-id="false"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In this paper, we establish the almost sure convergence of two-timescale stochastic gradient descent algorithms in continuous time under general noise and stability conditions, extending well known results in discrete time. We analyse algorithms with additive noise and those with non-additive noise. In the non-additive case, our analysis is carried out under the assumption that the noise is a continuous-time Markov process, controlled by the algorithm states. The algorithms we consider can be applied to a broad class of bilevel optimisation problems. We study one such problem in detail, namely, the problem of joint online parameter estimation and optimal sensor placement for a partially observed diffusion process. We demonstrate how this can be formulated as a bilevel optimisation problem, and propose a solution in the form of a continuous-time, two-timescale, stochastic gradient descent algorithm. Furthermore, under suitable conditions on the latent signal, the filter, and the filter derivatives, we establish almost sure convergence of the online parameter estimates and optimal sensor placements to the stationary points of the asymptotic log-likelihood and asymptotic filter covariance, respectively. We also provide numerical examples, illustrating the application of the proposed methodology to a partially observed Beneš equation, and a partially observed stochastic advection-diffusion equation.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge"><a href="https://icml.cc/" rel="external nofollow noopener" target="_blank">ICML</a></abbr></div>

        <!-- Entry bib key -->
        <div id="Sharrock2023" class="col-sm-8">
        <!-- Title -->
        <div class="title">Coin Sampling: Gradient-Based Bayesian Inference without Learning Rates</div>
        <!-- Author -->
        <div class="author">
        

        <em>Louis Sharrock</em>, and <a href="https://chris-nemeth.github.io/" rel="external nofollow noopener" target="_blank">Christopher Nemeth</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Proceedings of the 40th International Conference on Machine Learning (ICML 2023)</em>, 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2301.11294" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="https://proceedings.mlr.press/v202/sharrock23a.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
            <a href="https://github.com/louissharrock/Coin-SVGD" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
            <a href="/assets/pdf/coin-poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a>
            <a href="/assets/pdf/coin_slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-arxiv-id="2301.11294"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In recent years, particle-based variational inference (ParVI) methods such as Stein variational gradient descent (SVGD) have grown in popularity as scalable methods for Bayesian inference. Unfortunately, the properties of such methods invariably depend on hyperparameters such as the learning rate, which must be carefully tuned by the practitioner in order to ensure convergence to the target measure at a suitable rate. In this paper, we introduce a suite of new particle-based methods for scalable Bayesian inference based on coin betting, which are entirely learning-rate free. We illustrate the performance of our approach on a range of numerical examples, including several high-dimensional models and datasets, demonstrating comparable performance to other ParVI algorithms with no need to tune a learning rate.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge"><a href="https://neurips.cc/" rel="external nofollow noopener" target="_blank">NeurIPS</a></abbr></div>

        <!-- Entry bib key -->
        <div id="Sharrock2023a" class="col-sm-8">
        <!-- Title -->
        <div class="title">Learning Rate Free Sampling in Constrained Domains</div>
        <!-- Author -->
        <div class="author">
        

        <em>Louis Sharrock</em>, <a href="https://web.stanford.edu/~lmackey/index.html" rel="external nofollow noopener" target="_blank">Lester Mackey</a>, and <a href="https://chris-nemeth.github.io/" rel="external nofollow noopener" target="_blank">Christopher Nemeth</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Proceedings of the 37th Conference on Neural Information Processing Systems (NeurIPS 2023)</em>, 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2305.14943" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="https://openreview.net/forum?id=TNAGFUcSP7" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
            <a href="https://github.com/louissharrock/constrained-coin-sampling" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-altmetric-id="false"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We introduce a suite of new particle-based algorithms for sampling in constrained domains which are entirely learning rate free. Our approach leverages coin betting ideas from convex optimisation, and the viewpoint of constrained sampling as a mirrored optimisation problem on the space of probability measures. Based on this viewpoint, we also introduce a unifying framework for several existing constrained sampling algorithms, including mirrored Langevin dynamics and mirrored Stein variational gradient descent. We demonstrate the performance of our algorithms on a range of numerical examples, including sampling from targets on the simplex, sampling with fairness constraints, and constrained sampling problems in post-selection inference. Our results indicate that our algorithms achieve competitive performance with existing constrained sampling methods, without the need to tune any hyperparameters.</p>
          </div>
        </div>
      </div>
</li>
</ol>
          </div>


          <!-- Social -->
            <div class="social">
              <div class="contact-icons">
                <a href="mailto:%6C.%73%68%61%72%72%6F%63%6B@%6C%61%6E%63%61%73%74%65%72.%61%63.%75%6B" title="email"><i class="fas fa-envelope"></i></a>
            <a href="https://scholar.google.com/citations?user=O0xSdYcAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a>
            <a href="https://github.com/louissharrock" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a>
            <a href="https://www.linkedin.com/in/louissharrock" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fab fa-linkedin"></i></a>
            <a href="https://twitter.com/Louis_Sharrock" title="Twitter" rel="external nofollow noopener" target="_blank"><i class="fab fa-twitter"></i></a>
            

              </div>

              <div class="contact-note">
                The best way to reach me is via <a href="mailto:%20l.sharrock@lancaster.ac.uk">email</a>.

              </div>

            </div>
        </article>

</div>

      
    </div>

    <!-- Footer -->    <footer class="sticky-bottom mt-5">
      <div class="container">
        © Copyright 2024 Louis  Sharrock. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
